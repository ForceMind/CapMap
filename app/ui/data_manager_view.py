from datetime import datetime

import streamlit as st

from core.data_access import (
    DEFAULT_MIN_PERIOD,
    _get_cached_codes_for_date,
    _get_daily_codes,
    _scan_cached_dates,
    _start_manual_prefetch,
)


def render_data_manager(origin_df):
    st.subheader("ğŸ“¦ æœ¬åœ°æ•°æ®ç®¡ç†ä¸æ¦‚è§ˆ")
    
    tab1, tab2 = st.tabs(["ğŸ“… æ—¥çº¿ç¼“å­˜æ¦‚è§ˆ", "â±ï¸ åˆ†æ—¶æ•°æ®è¯¦æƒ…"])
    
    if origin_df is None or origin_df.empty:
        st.warning("æš‚æ— å†å²æ•°æ®ï¼Œè¯·å…ˆåˆå§‹åŒ–ã€‚")
        return

    all_dates = sorted(origin_df['æ—¥æœŸ'].dt.date.unique())

    with tab1:
        st.metric("æ€»äº¤æ˜“å¤©æ•°", len(all_dates))
        st.write(f"æ—¶é—´è·¨åº¦: {all_dates[0]} è‡³ {all_dates[-1]}")
        
        # ç®€å•çš„çƒ­åŠ›å›¾æˆ–åˆ—è¡¨æ˜¾ç¤ºç¼ºå¤±æƒ…å†µ (å‡è®¾ origin_df æ˜¯è¿ç»­æ‹‰å–çš„ï¼Œ
        # å¦‚æœä¸­é—´æœ‰æ–­å±‚ï¼Œå¯ä»¥é€šè¿‡ date_range å¯¹æ¯”)
        # è¿™é‡Œä¸»è¦å±•ç¤ºæ˜¯å¦æœ‰æŸå¤©æ•°æ®é‡å¼‚å¸¸ (æ¯”å¦‚åªæœ‰å‡ ç™¾åªè‚¡ç¥¨)
        
        # ç»Ÿè®¡æ¯å¤©çš„è‚¡ç¥¨æ•°é‡
        daily_counts = origin_df.groupby(origin_df['æ—¥æœŸ'].dt.date).size().reset_index(name='count')
        
        # æ‰¾å‡ºæ•°é‡è¾ƒå°‘çš„å¤© (å¯èƒ½æ•°æ®ä¸å…¨)
        threshold = 200 # å‡è®¾å°‘äº200åªè®¤ä¸ºå¼‚å¸¸
        suspicious_days = daily_counts[daily_counts['count'] < threshold]
        
        if not suspicious_days.empty:
            st.error(f"å‘ç° {len(suspicious_days)} ä¸ªäº¤æ˜“æ—¥æ•°æ®é‡å¼‚å¸¸åä½ (V2 repair enabled):")
            st.dataframe(suspicious_days)
        else:
            st.success("æ—¥çº¿æ•°æ®è¦†ç›–çœ‹èµ·æ¥æ­£å¸¸ (æ¯å¤© > 200 åªè‚¡ç¥¨).")

        st.line_chart(daily_counts.set_index('æ—¥æœŸ'))

    with tab2:
        st.caption("åˆ†æ—¶æ•°æ® (Minutes) ç¼“å­˜è¦†ç›–ç‡æŸ¥è¯¢")
        
        col_d1, col_d2 = st.columns([1, 2])
        with col_d1:
            date_strs = [d.strftime("%Y-%m-%d") for d in all_dates]
            # é»˜è®¤é€‰æœ€è¿‘ä¸€å¤©
            selected_date_str = st.selectbox("é€‰æ‹©äº¤æ˜“æ—¥æœŸ", date_strs, index=len(date_strs) - 1)
        
        selected_date = datetime.strptime(selected_date_str, "%Y-%m-%d").date()
        date_key = selected_date_str.replace("-", "")
        
        # è·å–å½“æ—¥åº”æœ‰çš„è‚¡ç¥¨
        codes, name_map = _get_daily_codes(origin_df, selected_date)
        
        # è·å–å®é™…ç¼“å­˜
        cached_codes = _get_cached_codes_for_date(date_key, codes, period=DEFAULT_MIN_PERIOD, is_index=False)
        
        # æŒ‡æ•°ç¼“å­˜
        indices = ["000300", "000001", "399001", "000905", "000852"]
        cached_indices = _get_cached_codes_for_date(date_key, indices, period=DEFAULT_MIN_PERIOD, is_index=True)
        
        with col_d2:
            st.write(f"### {selected_date_str}")
            c1, c2 = st.columns(2)
            c1.metric("æŒ‡æ•°è¦†ç›–", f"{len(cached_indices)} / {len(indices)}")
            c2.metric("ä¸ªè‚¡è¦†ç›–", f"{len(cached_codes)} / {len(codes)}")
            
            if len(cached_codes) < len(codes):
                st.progress(len(cached_codes) / len(codes))
            else:
                st.progress(1.0)
        
        st.divider()
        
        miss_col, exist_col = st.columns(2)
        with miss_col:
            missing_codes = sorted(list(set(codes) - set(cached_codes)))
            st.warning(f"ç¼ºå¤±è‚¡ç¥¨ ({len(missing_codes)})")
            if missing_codes:
                st.text_area("ç¼ºå¤±ä»£ç åˆ—è¡¨", ",".join(missing_codes), height=150)
                if st.button("ğŸš€ ä»…è¡¥å…¨ç¼ºå¤±æ•°æ®"):
                    _start_manual_prefetch([selected_date], origin_df)
        
        with exist_col:
             st.success(f"å·²ç¼“å­˜è‚¡ç¥¨ ({len(cached_codes)})")
             st.text_area("å·²ç¼“å­˜ä»£ç é¢„è§ˆ", ",".join(list(cached_codes)[:500]) + ("..." if len(cached_codes)>500 else ""), height=150)

        if missing_codes:
            missing_lines = [f"{c} {name_map.get(c, c)}" for c in missing_codes]
            st.text_area("ç¼ºå¤±è‚¡ç¥¨", "\n".join(missing_lines), height=160)
        else:
            st.success("è‚¡ç¥¨åˆ†æ—¶å·²å®Œæ•´ã€‚")

        index_codes = ["000300", "000001", "399001"]
        cached_idx = _get_cached_codes_for_date(date_key, index_codes, period=DEFAULT_MIN_PERIOD, is_index=True)
        missing_idx = [c for c in index_codes if c not in cached_idx]
        st.write(f"æŒ‡æ•°åˆ†æ—¶ç¼“å­˜: {len(cached_idx)}/{len(index_codes)}")
        if missing_idx:
            st.warning("ç¼ºå¤±æŒ‡æ•°: " + ", ".join(missing_idx))
        else:
            st.success("æŒ‡æ•°åˆ†æ—¶å·²å®Œæ•´ã€‚")

        st.markdown("### æ‰‹åŠ¨è¡¥é½")
        include_indices = st.checkbox("åŒ…å«æŒ‡æ•°", value=True)
        default_codes = missing_codes[:20]
        select_codes = st.multiselect("é€‰æ‹©è¦è¡¥é½çš„è‚¡ç¥¨(ç¼ºå¤±)", options=missing_codes, default=default_codes)
        if st.button("å¯åŠ¨åå°è¡¥é½"):
            started = _start_manual_prefetch(selected_date_str, select_codes, name_map, include_indices=include_indices)
            if started:
                st.info("å·²å¯åŠ¨åå°è¡¥é½ï¼Œè¯·æŸ¥çœ‹ logs/app.logã€‚")
            else:
                st.warning("æ²¡æœ‰å¯è¡¥é½çš„ä»»åŠ¡ã€‚")

        with st.expander("æœ¬åœ°åˆ†æ—¶ç¼“å­˜æ—¥æœŸ"):
            cached_dates = _scan_cached_dates(period=DEFAULT_MIN_PERIOD, is_index=False)
            if cached_dates:
                readable = [d[:4] + '-' + d[4:6] + '-' + d[6:] for d in cached_dates]
                st.text_area("ç¼“å­˜æ—¥æœŸ", "\n".join(readable), height=120)
            else:
                st.write("æš‚æ— æœ¬åœ°åˆ†æ—¶ç¼“å­˜ã€‚")
