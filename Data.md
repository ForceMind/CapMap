1. 历史数据同步（全量/增量）
入口
主要逻辑在“全局数据初始化”部分，通常在程序启动或用户点击同步时触发。
相关函数如 get_csi300_history_data（或类似命名）。
线程模型
单线程：历史数据的同步是串行的，按股票代码逐个拉取，未使用并发。
主要流程：
获取沪深300成分股列表（通过 akshare）。
遍历每只股票，依次调用 akshare 的日线接口获取历史数据。
若有新数据，合并到本地缓存（parquet 文件）。
进度条和状态提示通过 Streamlit 组件实时反馈。
细节
若接口失败，会尝试用缓存数据兜底。
若当天有实时数据，会补充到 DataFrame。
数据保存采用本地文件，避免重复拉取。
2. 分时数据（分钟线）拉取
入口
主要在“加载分时走势”相关的 checkbox 选中后触发。
相关函数如 fetch_cached_min_data、fetch_intraday_data_v2。
线程模型
多线程并发：分时数据拉取采用 concurrent.futures.ThreadPoolExecutor，并发获取多只股票/指数的分钟线数据。
线程数一般设置为 10~16，防止被数据源封禁。
主要流程
根据选股模式（如成交额Top/指数贡献Top）筛选出沪深各Top N只股票。
构造任务列表（股票+指数）。
用线程池并发调用 fetch_cached_min_data 拉取每只股票/指数的分钟线数据。
每个线程都通过 add_script_run_ctx 绑定 Streamlit 上下文，避免多线程下的上下文丢失。
拉取完成后，合并数据，进行后续的可视化处理。
细节
每只股票/指数的数据单独缓存，避免重复请求。
有重试和退避机制，防止接口频繁失败。
进度条和状态提示实时反馈。
总结
历史数据同步：单线程，串行拉取，适合数据量大但不频繁变动的场景。
分时数据拉取：多线程并发，适合需要快速获取大量分钟线数据的场景。
同步数据时，会优先用缓存，只有缺失或过期才会真正访问网络接口，保证效率和稳定性。