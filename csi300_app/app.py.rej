diff a/csi300_app/app.py b/csi300_app/app.py	(rejected hunks)
@@ -480,347 +480,435 @@
                 return {
                     'code': task['code'],
                     'name': task['name'],
                     'data': data,
                     'turnover': task['to_val'],
                     'is_index': is_index
                 }
         except Exception:
             pass
         return None
 
     # å¹¶å‘æ‰§è¡Œ
     # çº¿ç¨‹æ•°ä¸å®œè¿‡å¤šï¼Œä»¥å…è§¦å‘åçˆ¬é™åˆ¶ï¼Œ10-20å·¦å³è¾ƒä¸ºå®‰å…¨
     ctx = get_script_run_ctx()
     def _worker_wrapper(t):
         if ctx:
             add_script_run_ctx(threading.current_thread(), ctx)
         return _worker(t)
 
     with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:
         future_to_task = {executor.submit(_worker_wrapper, t): t for t in tasks}
         
         for future in concurrent.futures.as_completed(future_to_task):
             res = future.result()
             if res:
                 results.append(res)
             
     return results
 
 # 2. UI å¸ƒå±€
 # -----------------------------------------------------------------------------
 
 st.title("Aè‚¡å†å²ç›˜é¢å›æ”¾ç³»ç»Ÿ (æ²ªæ·±300 Market Replay)")
 
 st.markdown("""
 > ğŸ•¹ï¸ **æ“ä½œæŒ‡å—**ï¼š
 > 1. ç­‰å¾…æ•°æ®åˆå§‹åŒ–å®Œæˆï¼ˆåˆæ¬¡è¿è¡Œå¯èƒ½éœ€è¦ 2-3 åˆ†é’Ÿï¼‰ã€‚
 > 2. æ‹–åŠ¨ä¸‹æ–¹æ»‘å—é€‰æ‹©å†å²æ—¥æœŸã€‚
 > 3. è§‚å¯Ÿå½“æ—¥ç›˜é¢çš„èµ„é‡‘æµå‘ä¸çƒ­åº¦ã€‚
 """)
 
 # ä¾§è¾¹æ 
 with st.sidebar:
     st.header("âš™ï¸ æ•°æ®ç®¡ç†")
     
     with st.expander("æ•°æ®åˆ·æ–°ä¸ç»´æŠ¤", expanded=True):
         st.write("å¦‚æœæ•°æ®æ˜¾ç¤ºä¸æ­£ç¡®ï¼Œè¯·å°è¯•ä»¥ä¸‹æ“ä½œï¼š")
         
         # 1. åˆ·æ–°ç›˜ä¸­
         if st.button("ğŸŸ¢ åˆ·æ–°ä»Šæ—¥è¡Œæƒ… (ç›˜ä¸­)"):
             try:
                 if os.path.exists(CACHE_FILE):
                     # è¯»å–å¹¶åˆ é™¤ä»Šå¤©çš„è®°å½•ï¼Œå¼ºåˆ¶ä¸‹æ¬¡åŠ è½½æ—¶è§¦å‘å¢é‡æ›´æ–°
                     _df = pd.read_parquet(CACHE_FILE)
                     _today = datetime.now().date()
                     # è¿‡æ»¤æ‰ >= ä»Šå¤©çš„æ•°æ®
                     _df_new = _df[_df['æ—¥æœŸ'].dt.date < _today]
                     _df_new.to_parquet(CACHE_FILE)
                     st.toast("å·²æ¸…é™¤ä»Šæ—¥ç¼“å­˜ï¼Œæ­£åœ¨é‡æ–°æ‹‰å–å®æ—¶æ•°æ®...")
                 st.cache_data.clear() # å³ä½¿æ˜¯åˆ†æ—¶æ•°æ®æœ€å¥½ä¹Ÿæ¸…ä¸€ä¸‹ï¼Œä»¥é˜²ä¸‡ä¸€
                 st.rerun()
             except Exception as e:
                 st.error(f"æ“ä½œå¤±è´¥: {e}")
 
         # 2. æ¸…ç†åˆ†æ—¶ç¼“å­˜
         if st.button("ğŸ§¹ æ¸…ç©ºåˆ†æ—¶å›¾ç¼“å­˜"):
             st.cache_data.clear()
             st.toast("âœ… æ‰€æœ‰å†…å­˜ç¼“å­˜å·²æ¸…ç©ºï¼Œä¸‹æ¬¡æŸ¥çœ‹åˆ†æ—¶å›¾å°†é‡æ–°ä¸‹è½½ã€‚")
 
         # 3. ç¡¬é‡ç½®
         if st.button("ğŸš¨ å½»åº•é‡ç½® (åˆ é™¤æ‰€æœ‰)"):
             if os.path.exists(CACHE_FILE):
                 os.remove(CACHE_FILE)
                 st.toast("å·²åˆ é™¤æœ¬åœ°æ‰€æœ‰å†å²æ•°æ®ã€‚")
             st.cache_data.clear()
             st.rerun()
 
     st.info("æ•°æ®æºï¼šæ²ªæ·±300æˆåˆ†è‚¡ (AkShare)")
     st.caption("æ³¨ï¼šæ–¹å—å¤§å°ä½¿ç”¨'æˆäº¤é¢'ä»£æ›¿'å¸‚å€¼'ï¼Œ\nåæ˜ å½“æ—¥äº¤æ˜“çƒ­åº¦ã€‚")
 
     st.markdown("---")
     st.markdown("### ğŸ› ï¸ æ¿å—è¿‡æ»¤")
     filter_cyb = st.checkbox("å±è”½åˆ›ä¸šæ¿ (300å¼€å¤´)", value=False)
     filter_kcb = st.checkbox("å±è”½ç§‘åˆ›æ¿ (688å¼€å¤´)", value=False)
     
 # åŠ è½½æ•°æ®
 with st.spinner("æ­£åœ¨åˆå§‹åŒ–å†å²æ•°æ®ä»“åº“..."):
     origin_df = fetch_history_data()
 
 # --- åå°ä»»åŠ¡æ£€æµ‹ä¸æ§åˆ¶ ---
 # æ£€æŸ¥æ˜¯å¦æœ‰åä¸º "PrefetchWorker" çš„åå°çº¿ç¨‹
 bg_thread = None
 for t in threading.enumerate():
     if t.name == "PrefetchWorker":
         bg_thread = t
         break
 
 # æ›´æ–° Sidebar UI
 with st.sidebar:
     st.markdown("---")
+    
+    # å¯¼èˆªæ 
+    nav_option = st.radio("ğŸ“¡ åŠŸèƒ½å¯¼èˆª", ["âª å†å²ç›˜é¢å›æ”¾", "ğŸŒŠ èµ„é‡‘åç¦»åˆ†æ"], index=0)
+    
     with st.expander("ğŸ“¥ åå°æ•°æ®é¢„å–", expanded=False):
         st.caption("åå°é™é»˜ä¸‹è½½æœ€è¿‘ N å¤©åˆ†æ—¶æ•°æ®")
         prefetch_days = st.number_input("é¢„å–å¤©æ•°", min_value=5, max_value=200, value=30, step=10)
         
         if bg_thread and bg_thread.is_alive():
             st.info(f"ğŸŸ¢ åå°ä»»åŠ¡è¿è¡Œä¸­...\nè¯·å…³æ³¨æ§åˆ¶å°(Console)æ—¥å¿—")
             # æ— æ³•é€šè¿‡ Button åœæ­¢çº¿ç¨‹ï¼Œé™¤éä½¿ç”¨ Eventã€‚æš‚ä¸å®ç°åœæ­¢ã€‚
         else:
             if st.button("ğŸš€ å¯åŠ¨åå°ä¸‹è½½"):
                 if not origin_df.empty:
                     # è·å–æ—¥æœŸåˆ—è¡¨
                     all_dates = sorted(origin_df['æ—¥æœŸ'].dt.date.unique())
                     target_prefetch_dates = all_dates[-prefetch_days:]
                     
                     # å¯åŠ¨çº¿ç¨‹
                     t = threading.Thread(
                         target=background_prefetch_task,
                         args=(target_prefetch_dates, origin_df),
                         name="PrefetchWorker",
                         daemon=True
                     )
                     add_script_run_ctx(t)
                     t.start()
                     st.rerun()
                 else:
                     st.error("å†å²æ•°æ®å°šæœªå°±ç»ª")
 
 if not origin_df.empty:
     # --- å…¨å±€è¿‡æ»¤é€»è¾‘ ---
     df = origin_df.copy()
     if filter_cyb:
         df = df[~df['ä»£ç '].astype(str).str.startswith('300')]
     if filter_kcb:
         df = df[~df['ä»£ç '].astype(str).str.startswith('688')]
 
     if df.empty:
         st.warning("è¿‡æ»¤åæ²¡æœ‰å‰©ä½™è‚¡ç¥¨æ•°æ®ï¼Œè¯·å–æ¶ˆå‹¾é€‰è¿‡æ»¤é€‰é¡¹ã€‚")
         st.stop()
 
     # --- æ—¶é—´é€‰æ‹©å™¨é€»è¾‘ (Session State ç®¡ç†) ---
     available_dates = sorted(df['æ—¥æœŸ'].dt.date.unique())
     
+    if nav_option == "âª å†å²ç›˜é¢å›æ”¾":
         if 'selected_date_idx' not in st.session_state:
             st.session_state.selected_date_idx = len(available_dates) - 1
 
         #ç¡®ä¿ç´¢å¼•ä¸è¶Šç•Œ
         if st.session_state.selected_date_idx >= len(available_dates):
             st.session_state.selected_date_idx = len(available_dates) - 1
         if st.session_state.selected_date_idx < 0:
             st.session_state.selected_date_idx = 0
 
         # å¸ƒå±€ï¼šå‰ä¸€å¤© | æ»‘å— | åä¸€å¤©
         st.markdown("### ğŸ“… é€‰æ‹©å›æ”¾æ—¥æœŸ")
         
         # æ¨¡å¼é€‰æ‹©
         mode_col1, mode_col2 = st.columns([1, 3])
         with mode_col1:
             playback_mode = st.radio("å›æ”¾æ¨¡å¼", ["å•æ—¥å¤ç›˜", "å¤šæ—¥èµ°åŠ¿æ‹¼æ¥"], horizontal=True)
 
         if playback_mode == "å•æ—¥å¤ç›˜":
             col_prev, col_slider, col_next = st.columns([1, 6, 1])
             
             with col_prev:
                 st.write("") 
                 st.write("")
                 if st.button("â¬…ï¸ å‰ä¸€å¤©"):
                     if st.session_state.selected_date_idx > 0:
                         st.session_state.selected_date_idx -= 1
                         st.rerun()
 
             with col_next:
                 st.write("")
                 st.write("")
                 if st.button("åä¸€å¤© â¡ï¸"):
                     if st.session_state.selected_date_idx < len(available_dates) - 1:
                         st.session_state.selected_date_idx += 1
                         st.rerun()
 
             with col_slider:
                 # åŸ select_slider æ›¿æ¢ä¸º date_input ä»¥æ”¯æŒå¿«é€Ÿå¹´ä»½é€‰æ‹©
                 current_date_val = available_dates[st.session_state.selected_date_idx]
                 
                 picked_date = st.date_input(
                     "æ—¥æœŸ",
                     value=current_date_val,
                     min_value=available_dates[0],
                     max_value=available_dates[-1],
                     label_visibility="collapsed"
                 )
                 
                 # å¦‚æœæ—¥æœŸå‘ç”Ÿå˜åŒ–
                 if picked_date != current_date_val:
                     if picked_date in available_dates:
                         st.session_state.selected_date_idx = available_dates.index(picked_date)
                     else:
                         # å¦‚æœé€‰ä¸­çš„æ˜¯éäº¤æ˜“æ—¥ï¼Œå¯»æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥
                         closest_date = min(available_dates, key=lambda d: abs(d - picked_date))
                         st.session_state.selected_date_idx = available_dates.index(closest_date)
                         st.toast(f"ğŸ“… ä¼‘å¸‚æ—¥ï¼Œå·²è‡ªåŠ¨å®šä½åˆ°æœ€è¿‘äº¤æ˜“æ—¥: {closest_date}")
                     st.rerun()
             
             target_dates = [available_dates[st.session_state.selected_date_idx]] # ä½¿ç”¨ state ä¸­çš„æ—¥æœŸ
             selected_date = target_dates[0]
+            display_date_str = selected_date.strftime("%Y-%m-%d")
             
         else: # å¤šæ—¥èµ°åŠ¿æ‹¼æ¥
             with mode_col2:
                 date_range = st.date_input(
                     "é€‰æ‹©æ—¶é—´èŒƒå›´ (å»ºè®®ä¸è¶…è¿‡5å¤©ï¼Œå¦åˆ™åŠ è½½è¾ƒæ…¢)",
                     value=[available_dates[-5] if len(available_dates)>5 else available_dates[0], available_dates[-1]],
                     min_value=available_dates[0],
                     max_value=available_dates[-1]
                 )
             
             if len(date_range) == 2:
                 start_d, end_d = date_range
                 # ç­›é€‰å‡ºèŒƒå›´å†…çš„äº¤æ˜“æ—¥
                 target_dates = [d for d in available_dates if start_d <= d <= end_d]
                 if not target_dates: # å¦‚æœé€‰å®šçš„èŒƒå›´å†…æ²¡æœ‰äº¤æ˜“æ—¥ (ä¾‹å¦‚å…¨é€‰äº†å‡æœŸ)
                     st.warning("âš ï¸ é€‰å®šèŒƒå›´å†…æ— äº¤æ˜“æ•°æ®ï¼Œå·²è‡ªåŠ¨é‡ç½®ä¸ºæœ€è¿‘äº¤æ˜“æ—¥")
                     target_dates = [available_dates[-1]]
                 
                 st.info(f"å·²é€‰æ‹© {len(target_dates)} ä¸ªäº¤æ˜“æ—¥è¿›è¡Œæ‹¼æ¥å±•ç¤º")
-            selected_date = target_dates[-1] # ç”¨äºä¸‹æ–¹æ˜¾ç¤ºç»Ÿè®¡é¢æ¿çš„åŸºå‡†
+                selected_date = target_dates[-1] # ç”¨äºä¸‹æ–¹æ˜¾ç¤ºç»Ÿè®¡é¢æ¿çš„åŸºå‡† (å…¼å®¹æ—§ä»£ç å˜é‡å)
+                display_date_str = f"{target_dates[0].strftime('%Y%m%d')} ~ {target_dates[-1].strftime('%Y%m%d')}"
             else:
                 st.warning("è¯·é€‰æ‹©å®Œæ•´çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸ")
                 target_dates = [available_dates[-1]]
                 selected_date = available_dates[-1]
+                display_date_str = selected_date.strftime("%Y-%m-%d")
 
-    # --- æ•°æ®åˆ‡ç‰‡ä¸ç»Ÿè®¡ (ä»¥æœ€åä¸€å¤©æˆ–é€‰ä¸­æ—¥ä¸ºå‡†) ---
+        # --- æ•°æ®åˆ‡ç‰‡ä¸ç»Ÿè®¡ (å…¼å®¹å•æ—¥ä¸å¤šæ—¥) ---
+        if len(target_dates) == 1:
+            # å•æ—¥é€»è¾‘
             daily_df = df[df['æ—¥æœŸ'].dt.date == selected_date].copy()
-    
             if daily_df.empty:
-        st.warning(f"{selected_date} å½“æ—¥æ— äº¤æ˜“æ•°æ®ï¼ˆå¯èƒ½æ˜¯éäº¤æ˜“æ—¥æˆ–æ•°æ®ç¼ºå¤±ï¼‰ã€‚")
-    else:
-        # å½“æ—¥ç»Ÿè®¡æŒ‡æ ‡
+                st.warning(f"{selected_date} å½“æ—¥æ— äº¤æ˜“æ•°æ®ã€‚")
+                st.stop()
+                
             median_chg = daily_df['æ¶¨è·Œå¹…'].median()
-        total_turnover = daily_df['æˆäº¤é¢'].sum() / 1e8 # äº¿å…ƒ
+            total_turnover = daily_df['æˆäº¤é¢'].sum() / 1e8 
             top_gainer = daily_df.loc[daily_df['æ¶¨è·Œå¹…'].idxmax()]
-        top_loser = daily_df.loc[daily_df['æ¶¨è·Œå¹…'].idxmin()]
+            
+            metric_label_date = "å½“å‰å›æ”¾æ—¥æœŸ"
+            metric_label_chg = "æˆåˆ†è‚¡ä¸­ä½æ•°æ¶¨è·Œ"
+            metric_label_to = "æˆåˆ†è‚¡æ€»æˆäº¤"
+            
+        else:
+            # å¤šæ—¥é€»è¾‘ (è®¡ç®—ç´¯è®¡)
+            # 1. ç­›é€‰å‡ºèŒƒå›´å†…æ‰€æœ‰æ•°æ®
+            start_date_ts = pd.Timestamp(target_dates[0])
+            end_date_ts = pd.Timestamp(target_dates[-1])
+            
+            period_df = df[(df['æ—¥æœŸ'] >= start_date_ts) & (df['æ—¥æœŸ'] <= end_date_ts)].copy()
+            
+            if period_df.empty:
+                st.stop()
+                
+            # 2. è®¡ç®—åŒºé—´ç´¯è®¡æ¶¨è·Œå¹…
+            # æ–¹æ³•: å¯¹æ¯ä¸ªä»£ç ï¼Œæ‰¾åˆ°é¦–å°¾ä»·æ ¼
+            # æ³¨æ„: å¦‚æœåªç”¨ period_dfï¼Œé¦–æ—¥çš„æ•°æ®é‡Œçš„ 'æ”¶ç›˜' æ˜¯é¦–æ—¥çš„æ”¶ç›˜ä»·ã€‚
+            # åŒºé—´æ¶¨å¹… = (End_Close - Start_Close) / Start_Close ? 
+            # æˆ–è€…æ›´ç²¾ç¡®ï¼šStart_Close åº”è¯¥æ˜¯ Start_Date çš„ å‰ä¸€æ—¥æ”¶ç›˜ä»· (å³ Start_Open / (1+Start_Chg))?
+            # ç®€åŒ–èµ·è§ï¼Œæˆ‘ä»¬ç”¨ (End_Date Close - Start_Date Open) / Start_Date Open
+            # è¿™æ ·èƒ½åŒ…å« Start_Date å½“å¤©çš„æ¶¨è·Œ
+            
+            agg_stats = []
+            
+            # ä½¿ç”¨ groupby åŠ é€Ÿ
+            grouped = period_df.groupby('ä»£ç ')
+            
+            for code, group in grouped:
+                group = group.sort_values('æ—¥æœŸ')
+                if group.empty: continue
+                
+                first_row = group.iloc[0]
+                last_row = group.iloc[-1]
+                
+                # æ¨ç®—é¦–æ—¥å¼€ç›˜ä»· = æ”¶ç›˜ / (1 + chg/100)
+                # è¿™ç§åæ¨å¦‚æœæ˜¯æ¶¨åœæ¿å¤æƒå¯èƒ½å¾®å°è¯¯å·®ï¼Œä½†å¤Ÿç”¨ã€‚
+                # ä¹Ÿå¯ä»¥ç›´æ¥ç”¨ akshare ä¸‹è½½çš„ Openï¼Œä½†è¿™é‡Œåªæœ‰ Close/Chg
+                # å‡è®¾ Chg æ˜¯ç²¾ç¡®çš„
+                try:
+                    start_open = first_row['æ”¶ç›˜'] / (1 + first_row['æ¶¨è·Œå¹…']/100)
+                    end_close = last_row['æ”¶ç›˜']
+                    
+                    period_chg = (end_close - start_open) / start_open * 100
+                    period_turnover = group['æˆäº¤é¢'].sum()
+                    
+                    agg_stats.append({
+                        'ä»£ç ': code,
+                        'åç§°': first_row['åç§°'], # å‡è®¾æ²¡æ”¹å
+                        'åŒºé—´æ¶¨è·Œå¹…': period_chg,
+                        'åŒºé—´æ€»æˆäº¤': period_turnover
+                    })
+                except:
+                    pass
+            
+            agg_df = pd.DataFrame(agg_stats)
+            
+            if agg_df.empty:
+                st.warning("åŒºé—´æ•°æ®è®¡ç®—å¼‚å¸¸")
+                st.stop()
+                
+            median_chg = agg_df['åŒºé—´æ¶¨è·Œå¹…'].median()
+            total_turnover = period_df['æˆäº¤é¢'].sum() / 1e8
+            top_gainer = agg_df.loc[agg_df['åŒºé—´æ¶¨è·Œå¹…'].idxmax()]
+            
+            # ä¸ºäº†å…¼å®¹åç»­ daily_df çš„ä½¿ç”¨ (Treemap å’Œ é€‰è‚¡)
+            # æˆ‘ä»¬éœ€è¦æ„é€ ä¸€ä¸ª "Proxy Daily DF"
+            # è®©åé¢çš„é€‰è‚¡é€»è¾‘åŸºäº "åŒºé—´è¡¨ç°"
+            daily_df = agg_df.rename(columns={'åŒºé—´æ¶¨è·Œå¹…': 'æ¶¨è·Œå¹…', 'åŒºé—´æ€»æˆäº¤': 'æˆäº¤é¢'}).copy()
+            # è¡¥é½å…¶ä»–å­—æ®µ
+            # æ”¶ç›˜ä»·ç”¨æœ€åä¸€å¤©çš„
+            # daily_df è¿˜éœ€è¦ 'æ”¶ç›˜' ç”¨äºå±•ç¤º? Treemap hover éœ€è¦
+            # æˆ‘ä»¬å¯ä»¥ join å›å»ï¼Œä½† Treemap hover ä¹Ÿå¯ä»¥åªå±•ç¤ºæ¶¨è·Œ
+            daily_df['æ”¶ç›˜'] = 0 # Placeholder
+            
+            metric_label_date = "å½“å‰å›æ”¾åŒºé—´"
+            metric_label_chg = "åŒºé—´æ¶¨è·Œå¹…ä¸­ä½æ•°"
+            metric_label_to = "åŒºé—´æ€»æˆäº¤"
 
         # æ˜¾ç¤ºæŒ‡æ ‡è¡Œ
         col1, col2, col3, col4 = st.columns(4)
-        col1.metric("å½“å‰å›æ”¾æ—¥æœŸ", selected_date.strftime("%Y-%m-%d"))
-        col2.metric("æˆåˆ†è‚¡ä¸­ä½æ•°æ¶¨è·Œ", f"{median_chg:.2f}%", 
-                    delta=f"{median_chg:.2f}%", delta_color="normal") # Aè‚¡ä¹ æƒ¯éœ€ç»“åˆ Streamlit theme, ç”¨ normal éœ€è‡ªè¡Œè„‘è¡¥çº¢ç»¿
-        col3.metric("æˆåˆ†è‚¡æ€»æˆäº¤", f"{total_turnover:.1f} äº¿")
-        col4.metric("é¢†æ¶¨é¾™å¤´", f"{top_gainer['åç§°']} ({top_gainer['æ¶¨è·Œå¹…']:.2f}%)")
+        col1.metric(metric_label_date, display_date_str)
+        col2.metric(metric_label_chg, f"{median_chg:.2f}%", 
+                    delta=f"{median_chg:.2f}%", delta_color="normal")
+        col3.metric(metric_label_to, f"{total_turnover:.1f} äº¿")
+        col4.metric("é¢†æ¶¨é¾™å¤´", f"{top_gainer['åç§°']} ({'æ¶¨è·Œå¹…' in top_gainer and top_gainer['æ¶¨è·Œå¹…'] or top_gainer.get('åŒºé—´æ¶¨è·Œå¹…'):.2f}%)")
+
         # --- æ–°å¢åŠŸèƒ½ï¼šåˆ†æ—¶èµ°åŠ¿å åŠ  ---
         st.markdown("---")
         st.subheader("ğŸ“ˆ æ ¸å¿ƒèµ„äº§åˆ†æ—¶èµ°åŠ¿å åŠ ")
         
         # æ¨¡å¼é€‰æ‹©
         col_mode, col_num = st.columns([3, 1])
         with col_mode:
             chart_mode = st.radio("é€‰è‚¡æ¨¡å¼", ["æˆäº¤é¢ Top (æ´»è·ƒåº¦)", "æŒ‡æ•°è´¡çŒ® Top (å½±å“å¤§ç›˜)"], horizontal=True)
         with col_num:
             # æ·»åŠ  key é¿å… Bad setIn index é”™è¯¯ï¼Œå¹¶å¼ºåˆ¶é‡ç½®çŠ¶æ€
             top_n = st.number_input("æ ‡çš„æ•°é‡", min_value=5, max_value=50, value=20, step=5, 
                                    help="æ²ª/æ·±å„å– N ä¸ªæ ‡çš„ï¼ˆå³æ€»æ•°ä¸º 2Nï¼‰", key="top_n_stocks_input")
 
         st.caption(f"æ³¨ï¼šè¿™é‡Œçš„æ’åæ˜¯åŸºäº **{selected_date}** å½“æ—¥çš„æ•°æ®è®¡ç®—çš„ã€‚å¦‚æœæ˜¯å¤šæ—¥æ¨¡å¼ï¼Œåˆ™å±•ç¤ºè¿™äº›è‚¡ç¥¨åœ¨è¿‡å»å‡ å¤©çš„èµ°åŠ¿ã€‚")
         st.caption("æ³¨ï¼šæŒ‡æ•°è´¡çŒ® = æ¶¨è·Œå¹… Ã— æƒé‡(è¿‘ä¼¼ä¸ºæˆäº¤é¢/å¸‚å€¼å æ¯”)ã€‚æ­¤æ¨¡å¼èƒ½çœ‹åˆ°æ˜¯è°åœ¨æ‹‰åŠ¨æˆ–ç ¸ç›˜ã€‚")
 
         show_intraday = st.checkbox("åŠ è½½åˆ†æ—¶èµ°åŠ¿ (éœ€ä»ç½‘ç»œå®æ—¶æ‹‰å–)", value=False)
         
         if show_intraday:
             # ä½¿ç”¨ placeholder æ”¾ç½®è¿›åº¦æ¡ï¼Œé¿å…ç»„ä»¶é”€æ¯å¯¼è‡´çš„ç´¢å¼•é”™ä¹±
             progress_area = st.empty()
             
             # ç»Ÿä¸€é€‰è‚¡é€»è¾‘ï¼šæ— è®ºæ˜¯æˆäº¤é¢è¿˜æ˜¯æŒ‡æ•°è´¡çŒ®ï¼Œéƒ½æŒ‰æ²ªæ·±åˆ†åˆ«å– Top N
             if "æˆäº¤é¢" in chart_mode:
                 sort_col = 'æˆäº¤é¢'
             else:
                 daily_df['abs_impact'] = (daily_df['æ¶¨è·Œå¹…'] * daily_df['æˆäº¤é¢']).abs()
                 sort_col = 'abs_impact'
                 
             sh_pool = daily_df[daily_df['ä»£ç '].astype(str).str.startswith('6')].copy()
             sz_pool = daily_df[~daily_df['ä»£ç '].astype(str).str.startswith('6')].copy()
             
             sh_top = sh_pool.sort_values(sort_col, ascending=False).head(top_n)
             sz_top = sz_pool.sort_values(sort_col, ascending=False).head(top_n)
             
             top_stocks_df = pd.concat([sh_top, sz_top], ignore_index=True)
 
             target_stocks_list = []
             for _, row in top_stocks_df.iterrows():
                 target_stocks_list.append((row['ä»£ç '], row['åç§°'], row['æˆäº¤é¢'])) 
             
             all_intraday_data = [] 
             
             period_to_use = '1'
             
             if len(target_dates) > 5 and playback_mode == "å¤šæ—¥èµ°åŠ¿æ‹¼æ¥":
                 if len(target_dates) > 30:
                     period_to_use = '15' # è¶…è¿‡30å¤©ä½¿ç”¨15åˆ†é’Ÿçº¿
                     st.info(f"â„¹ï¸ æ‚¨é€‰æ‹©äº† {len(target_dates)} å¤©ï¼šç³»ç»Ÿè‡ªåŠ¨åˆ‡æ¢è‡³ã€15åˆ†é’Ÿçº§ã€‘æ•°æ®ã€‚")
                 else:
                     period_to_use = '5'
                     st.info(f"â„¹ï¸ æ‚¨é€‰æ‹©äº† {len(target_dates)} å¤©ï¼šç³»ç»Ÿè‡ªåŠ¨åˆ‡æ¢è‡³ã€5åˆ†é’Ÿçº§ã€‘æ•°æ®ã€‚")
             elif len(target_dates) > 10:
                  st.toast(f"âš ï¸ æ‚¨é€‰æ‹©äº† {len(target_dates)} å¤©çš„æ•°æ®ï¼ŒåŠ è½½å¯èƒ½è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…...")
             
             target_dates_to_fetch = target_dates
             total_steps = len(target_dates_to_fetch)
 
             # æ”¹å›æ‰å¹³åŒ–ç»“æ„ï¼Œä¸å†ä½¿ç”¨ containerï¼Œå‡å°‘ DOM æ“ä½œå±‚çº§
             # å¹¶å‘çº¿ç¨‹ä¸­ç¼“å­˜çš„ show_spinner=False å·²ç»è®¾ç½®ï¼Œè¿™é‡Œåº”è¯¥å®‰å…¨äº†
             status_text = st.empty()
             fetch_progress = st.progress(0)
                  
             for i, d_date in enumerate(target_dates_to_fetch):
                 status_text.text(f"ğŸ”„ æ­£åœ¨è·å–: {d_date.strftime('%Y-%m-%d')} ({i+1}/{total_steps})...")
                 fetch_progress.progress((i + 1) / total_steps)
                 
                 d_str = d_date.strftime("%Y-%m-%d")
                 day_results = fetch_intraday_data_v2(target_stocks_list, d_str, period=period_to_use)
                 
                 for res in day_results:
                         res['data']['date_col'] = d_str
                         res['real_date'] = d_date
                 
                 all_intraday_data.extend(day_results)
             
             # æ•°æ®æ‹‰å–å®Œæ¯•åï¼Œæ¸…é™¤è¿›åº¦ç»„ä»¶
             status_text.empty()
             fetch_progress.empty()
             # ç§»é™¤å¤–å±‚å ä½ç¬¦çš„æ¸…ç†ï¼Œå› ä¸ºå·²ç»ä¸å†ä½¿ç”¨
             progress_area.empty()
                 
             if not all_intraday_data:
                 st.warning("æœªèƒ½è·å–åˆ°åˆ†æ—¶æ•°æ®")
             else:
                     # --- æ•°æ®é‡ç»„ ---
                     # å°†åˆ†æ•£çš„æ•°æ®åˆå¹¶ä¸ºï¼š { 'code': { 'name':..., 'is_index':..., 'full_data': DataFrame } }
                     combined_series = {}
                     
                     for item in all_intraday_data:
                         code = item['code']
                         if code not in combined_series:
                             # æŸ¥æ‰¾è¯¥è‚¡ç¥¨åœ¨é€‰å®šæ—¥(æœ€åä¸€æ—¥)çš„æˆäº¤é¢ï¼Œç”¨äºå®šçº¿å®½
                             to_val = 0
                             if not item.get('is_index'):
                                 matches = daily_df[daily_df['ä»£ç '] == code]
                                 if not matches.empty:
                                     to_val = matches.iloc[0]['æˆäº¤é¢']
                             
                             combined_series[code] = {
